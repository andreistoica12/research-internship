{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all variables in the current environment (if you have already run some cells) - clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Replace the download directory of the NLTK tokenizer files with your preferred directory (I chose the root directory of the Research Internship project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andreistoica12/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/andreistoica12/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "from sentistrength import PySentiStr\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.data\n",
    "nltk.download('punkt')\n",
    "# Load the punkt tokenizer data from the local directory\n",
    "nltk.data.load('tokenizers/punkt/PY3/english.pickle')\n",
    "\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace with the path to the root folder of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir_path = '/home/andreistoica12/research-internship'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 1 subfolder to store important graphs. If it already existed (from previous runnings of the project), delete the folder and its contents and create an empty folder to store the current graphs, relevant to the current state of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_path = os.path.join(rootdir_path, 'graphs')\n",
    "if os.path.exists(graphs_path):\n",
    "   shutil.rmtree(graphs_path, ignore_errors=False, onerror=None)\n",
    "os.makedirs(graphs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covaxxy_graphs_path = os.path.join(graphs_path, 'covaxxy')\n",
    "if os.path.exists(covaxxy_graphs_path):\n",
    "   shutil.rmtree(covaxxy_graphs_path, ignore_errors=False, onerror=None)\n",
    "os.makedirs(covaxxy_graphs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "covaxxy_longitudinal_analysis_graphs = os.path.join(covaxxy_graphs_path, 'longitudinal-analysis')\n",
    "if os.path.exists(covaxxy_longitudinal_analysis_graphs):\n",
    "   shutil.rmtree(covaxxy_longitudinal_analysis_graphs, ignore_errors=False, onerror=None)\n",
    "os.makedirs(covaxxy_longitudinal_analysis_graphs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace with the path to the folder where we store the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = rootdir_path + '/data/covaxxy-csv-complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sentistrength = rootdir_path + '/SentiStrength'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sentistrength_jar = path_to_sentistrength + '/SentiStrengthCom.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sentistrength_language_folder = path_to_sentistrength + '/LanguageFolder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = rootdir_path + '/files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_replies_opinion_changes = files_path + '/replies_opinion_changes.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_stopwords = files_path + '/stopwords.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_stop_words(path_to_stopwords):\n",
    "    stop_words = set()\n",
    "    with open(path_to_stopwords, 'r') as f:\n",
    "        for line in f:\n",
    "            word = line.strip()  # remove whitespace and newline characters\n",
    "            stop_words.add(word)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = custom_stop_words(path_to_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I can use the predefined list of stopwords provided by NLTK, but it's for general purpose\n",
    "# # and the results when computing the sentiment are worse than expected, e.g. it considers\n",
    "# # words, such as \"not\" and \"all\" to be stopwords in contexts where they are actually important.\n",
    "# # So, I will use a custom stopwords list.\n",
    "# stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function remove_emoji() that takes a text string as input and uses a regular expression to match all Unicode characters that are classified as emojis. The regular expression includes different ranges of Unicode characters that represent different types of emojis, such as emoticons, symbols, and flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stop_words):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove the stopwords\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Join the filtered tokens back into a string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, stop_words):    \n",
    "    # 1. Lowercase all words in the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Replace the new line character with empty string\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    \n",
    "    # 3. Remove words starting with '@' - tags (most common noise in replies)\n",
    "    text = re.sub(r'@\\w+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 4. Remove words starting with 'http' - hyperlinks\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 5. Remove punctuation from the text using regular expressions\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # 6. Remove contractions, such as you're => you are\n",
    "    contractions.fix(text)\n",
    "\n",
    "    # 7. Remove emojis\n",
    "    text = remove_emoji(text)\n",
    "\n",
    "    # 8. Remove stopwords in English\n",
    "    text = remove_stopwords(text, stop_words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_by_date(path):\n",
    "        # Read the CSV file into a pandas dataframe\n",
    "        df_from_file = pd.read_csv(path, index_col= False)\n",
    "            \n",
    "        # Convert the \"created_at\" column to a pandas datetime object\n",
    "        df_from_file['created_at'] = pd.to_datetime(df_from_file['created_at'])\n",
    "\n",
    "        # Get all unique timestamp values from the \"created_at\" column\n",
    "        unique_dates = df_from_file['created_at'].dt.date.unique()\n",
    "\n",
    "        # Create a dictionary where the keys are the unique timestamp values\n",
    "        # and the values are dataframes that correspond to each unique timestamp value\n",
    "        days = {}\n",
    "        for date in unique_dates:\n",
    "            # Extract the rows that have the current timestamp value\n",
    "            mask = df_from_file['created_at'].dt.date == date\n",
    "            filtered_df = df_from_file[mask]\n",
    "            # Store the resulting subset of rows as a dataframe in the dictionary\n",
    "            days[date] = filtered_df\n",
    "        \n",
    "        return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_days(data_path):\n",
    "    # In order to read the data from the files, I need the paths of the files to be passed on to the read_csv() function. \n",
    "    # The order of the days in the file paths needs to be consistent with the order of the dates in the keys\n",
    "    file_paths = [ os.path.join(data_path, file) for file in os.listdir(data_path) ]\n",
    "\n",
    "    # Set the number of processes to run in parallel\n",
    "    num_processes = 10\n",
    "    # Create a pool of workers to execute the process_file function\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        # Use the pool to execute the process_file function on each file in parallel\n",
    "        results = pool.map(filter_df_by_date, file_paths)\n",
    "\n",
    "    days = dict()\n",
    "    for result in results:\n",
    "        days = {k: pd.concat([days.get(k, pd.DataFrame()), result.get(k, pd.DataFrame())]) for k in set(days) | set(result)}\n",
    "\n",
    "    # Dictionary comprehension to format datetime object keys to strings\n",
    "    days = {datetime_key.strftime('%d-%m-%Y'): df for datetime_key, df in days.items()}\n",
    "    \n",
    "    # Iterate over all the keys in the dictionary\n",
    "    for key in days.keys():\n",
    "        # Drop the \"id\" column from the dataframe corresponding to the key\n",
    "        days[key].drop('id', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = create_days(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_days(days):\n",
    "    # Here, I merged all data (from all available days) into a single dataframe (they have the same structure).\n",
    "    # I did that because some replies to a tweet posted today can come some days after, so we need to take care\n",
    "    # of the dataset as a whole.\n",
    "\n",
    "    \n",
    "    # Convert string keys to datetime objects and sort them\n",
    "    sorted_keys = sorted([datetime.strptime(k, '%d-%m-%Y') for k in days.keys()])\n",
    "\n",
    "    # Convert datetime objects back to string keys with format '%d-%m-%Y'\n",
    "    sorted_key_strings = [k.strftime('%d-%m-%Y') for k in sorted_keys]\n",
    "\n",
    "    # concatenate the dataframes and reset the index\n",
    "    merged_days = pd.concat([days[key] for key in sorted_key_strings], ignore_index=True)\n",
    "\n",
    "    # Convert string column to datetime\n",
    "    merged_days['created_at'] = pd.to_datetime(merged_days['created_at'])\n",
    "\n",
    "    return merged_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_days = create_merged_days(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>credible</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>urls</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_author_id</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>retweeted_screen_name</th>\n",
       "      <th>user_mentions_id</th>\n",
       "      <th>user_mentions_screen_name</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_tweet_id</th>\n",
       "      <th>in_reply_to_username</th>\n",
       "      <th>reference_type</th>\n",
       "      <th>reference_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-24 18:00:10+00:00</td>\n",
       "      <td>1364636249852502018</td>\n",
       "      <td>1</td>\n",
       "      <td>107501328</td>\n",
       "      <td>RT @Maricopahealth: At one of our community po...</td>\n",
       "      <td>#</td>\n",
       "      <td>2-1-1 Arizona</td>\n",
       "      <td>211arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>...</td>\n",
       "      <td>29816986</td>\n",
       "      <td>1364632754042802176</td>\n",
       "      <td>Maricopahealth</td>\n",
       "      <td>29816986</td>\n",
       "      <td>Maricopahealth</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1364632754042802176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-24 18:00:18+00:00</td>\n",
       "      <td>1364636282664574978</td>\n",
       "      <td>1</td>\n",
       "      <td>26761523</td>\n",
       "      <td>Ready for DAY 2 of State of the Valley? Join u...</td>\n",
       "      <td>jointventure.org,twitter.com,</td>\n",
       "      <td>Joint Venture SV</td>\n",
       "      <td>JointVentureSVN</td>\n",
       "      <td>False</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-24 18:00:30+00:00</td>\n",
       "      <td>1364636333596008449</td>\n",
       "      <td>1</td>\n",
       "      <td>1234926105234034689</td>\n",
       "      <td>RT @SteveStaeger: When #COVID19Colorado is ove...</td>\n",
       "      <td>#</td>\n",
       "      <td>Colorado Coronavirus Updates</td>\n",
       "      <td>COVIDinColorado</td>\n",
       "      <td>False</td>\n",
       "      <td>Denver, Colorado</td>\n",
       "      <td>...</td>\n",
       "      <td>182037688</td>\n",
       "      <td>1364293582157307906</td>\n",
       "      <td>SteveStaeger</td>\n",
       "      <td>182037688</td>\n",
       "      <td>SteveStaeger</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1364293582157307906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-24 18:03:16+00:00</td>\n",
       "      <td>1364637028948709377</td>\n",
       "      <td>1</td>\n",
       "      <td>1329106574082641920</td>\n",
       "      <td>#SD37: Starting next week, @OCHealth will star...</td>\n",
       "      <td>bit.ly,www.ocregister.com,</td>\n",
       "      <td>Senator Dave Min</td>\n",
       "      <td>SenDaveMin</td>\n",
       "      <td>True</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>36069538</td>\n",
       "      <td>ochealth</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-24 18:03:35+00:00</td>\n",
       "      <td>1364637110951583746</td>\n",
       "      <td>1</td>\n",
       "      <td>1363750425459970048</td>\n",
       "      <td>RT @jatinde45666597: Vaccination has been star...</td>\n",
       "      <td>#</td>\n",
       "      <td>Reena Sharma</td>\n",
       "      <td>write2reena</td>\n",
       "      <td>False</td>\n",
       "      <td>Auckland, New Zealand</td>\n",
       "      <td>...</td>\n",
       "      <td>1295748297529884673</td>\n",
       "      <td>1364087633538859008</td>\n",
       "      <td>jatinde45666597</td>\n",
       "      <td>1295748297529884673</td>\n",
       "      <td>jatinde45666597</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1364087633538859008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123691</th>\n",
       "      <td>2021-03-10 03:58:32+00:00</td>\n",
       "      <td>1369497876213067777</td>\n",
       "      <td>1</td>\n",
       "      <td>552510895</td>\n",
       "      <td>RT @abcadelaide: The first COVID-19 vaccine ha...</td>\n",
       "      <td>#</td>\n",
       "      <td>Brad Coates</td>\n",
       "      <td>Bandit2809</td>\n",
       "      <td>False</td>\n",
       "      <td>#</td>\n",
       "      <td>...</td>\n",
       "      <td>16213139</td>\n",
       "      <td>1369444755751469057</td>\n",
       "      <td>abcadelaide</td>\n",
       "      <td>16213139</td>\n",
       "      <td>abcadelaide</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1369444755751469057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123692</th>\n",
       "      <td>2021-03-10 03:58:32+00:00</td>\n",
       "      <td>1369497877119197186</td>\n",
       "      <td>1</td>\n",
       "      <td>1173226982999580672</td>\n",
       "      <td>RT @KizzyPhD: Thanks for making the informed c...</td>\n",
       "      <td>#</td>\n",
       "      <td>Edward Patrick Vogel</td>\n",
       "      <td>MathArt4All</td>\n",
       "      <td>False</td>\n",
       "      <td>55419</td>\n",
       "      <td>...</td>\n",
       "      <td>1215444012322172928</td>\n",
       "      <td>1369482754845466629</td>\n",
       "      <td>KizzyPhD</td>\n",
       "      <td>1215444012322172928</td>\n",
       "      <td>KizzyPhD</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1369482754845466629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123693</th>\n",
       "      <td>2021-03-10 03:58:32+00:00</td>\n",
       "      <td>1369497877349797894</td>\n",
       "      <td>1</td>\n",
       "      <td>1031738844230680576</td>\n",
       "      <td>RT @Ross_Greer: You live in a country where a ...</td>\n",
       "      <td>#</td>\n",
       "      <td>XoZXo</td>\n",
       "      <td>XoZXo2</td>\n",
       "      <td>False</td>\n",
       "      <td>#</td>\n",
       "      <td>...</td>\n",
       "      <td>50308678</td>\n",
       "      <td>1369409097213296652</td>\n",
       "      <td>Ross_Greer</td>\n",
       "      <td>50308678</td>\n",
       "      <td>Ross_Greer</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1369409097213296652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123694</th>\n",
       "      <td>2021-03-10 03:58:32+00:00</td>\n",
       "      <td>1369497877827977216</td>\n",
       "      <td>1</td>\n",
       "      <td>1291864731779837953</td>\n",
       "      <td>My mom got the vaccine...</td>\n",
       "      <td>#</td>\n",
       "      <td>October 5th üòåüá≠üáπ</td>\n",
       "      <td>Vie_de_martini</td>\n",
       "      <td>False</td>\n",
       "      <td>#</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123695</th>\n",
       "      <td>2021-03-10 03:58:32+00:00</td>\n",
       "      <td>1369497878108860416</td>\n",
       "      <td>1</td>\n",
       "      <td>1233294863166164994</td>\n",
       "      <td>RT @ByMikeBaker: NEW: Alaska is now making cov...</td>\n",
       "      <td>#</td>\n",
       "      <td>Tired of Stupid</td>\n",
       "      <td>Millie96015868</td>\n",
       "      <td>False</td>\n",
       "      <td>Reality</td>\n",
       "      <td>...</td>\n",
       "      <td>178065733</td>\n",
       "      <td>1369469803795124225</td>\n",
       "      <td>ByMikeBaker</td>\n",
       "      <td>178065733</td>\n",
       "      <td>ByMikeBaker</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1369469803795124225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5123696 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at             tweet_id  credible  \\\n",
       "0       2021-02-24 18:00:10+00:00  1364636249852502018         1   \n",
       "1       2021-02-24 18:00:18+00:00  1364636282664574978         1   \n",
       "2       2021-02-24 18:00:30+00:00  1364636333596008449         1   \n",
       "3       2021-02-24 18:03:16+00:00  1364637028948709377         1   \n",
       "4       2021-02-24 18:03:35+00:00  1364637110951583746         1   \n",
       "...                           ...                  ...       ...   \n",
       "5123691 2021-03-10 03:58:32+00:00  1369497876213067777         1   \n",
       "5123692 2021-03-10 03:58:32+00:00  1369497877119197186         1   \n",
       "5123693 2021-03-10 03:58:32+00:00  1369497877349797894         1   \n",
       "5123694 2021-03-10 03:58:32+00:00  1369497877827977216         1   \n",
       "5123695 2021-03-10 03:58:32+00:00  1369497878108860416         1   \n",
       "\n",
       "                   author_id  \\\n",
       "0                  107501328   \n",
       "1                   26761523   \n",
       "2        1234926105234034689   \n",
       "3        1329106574082641920   \n",
       "4        1363750425459970048   \n",
       "...                      ...   \n",
       "5123691            552510895   \n",
       "5123692  1173226982999580672   \n",
       "5123693  1031738844230680576   \n",
       "5123694  1291864731779837953   \n",
       "5123695  1233294863166164994   \n",
       "\n",
       "                                                      text  \\\n",
       "0        RT @Maricopahealth: At one of our community po...   \n",
       "1        Ready for DAY 2 of State of the Valley? Join u...   \n",
       "2        RT @SteveStaeger: When #COVID19Colorado is ove...   \n",
       "3        #SD37: Starting next week, @OCHealth will star...   \n",
       "4        RT @jatinde45666597: Vaccination has been star...   \n",
       "...                                                    ...   \n",
       "5123691  RT @abcadelaide: The first COVID-19 vaccine ha...   \n",
       "5123692  RT @KizzyPhD: Thanks for making the informed c...   \n",
       "5123693  RT @Ross_Greer: You live in a country where a ...   \n",
       "5123694                          My mom got the vaccine...   \n",
       "5123695  RT @ByMikeBaker: NEW: Alaska is now making cov...   \n",
       "\n",
       "                                  urls                          name  \\\n",
       "0                                    #                 2-1-1 Arizona   \n",
       "1        jointventure.org,twitter.com,              Joint Venture SV   \n",
       "2                                    #  Colorado Coronavirus Updates   \n",
       "3           bit.ly,www.ocregister.com,              Senator Dave Min   \n",
       "4                                    #                  Reena Sharma   \n",
       "...                                ...                           ...   \n",
       "5123691                              #                   Brad Coates   \n",
       "5123692                              #          Edward Patrick Vogel   \n",
       "5123693                              #                         XoZXo   \n",
       "5123694                              #               October 5th üòåüá≠üáπ   \n",
       "5123695                              #               Tired of Stupid   \n",
       "\n",
       "                username  verified               location  ...  \\\n",
       "0             211arizona     False                Arizona  ...   \n",
       "1        JointVentureSVN     False           San Jose, CA  ...   \n",
       "2        COVIDinColorado     False       Denver, Colorado  ...   \n",
       "3             SenDaveMin      True             Irvine, CA  ...   \n",
       "4            write2reena     False  Auckland, New Zealand  ...   \n",
       "...                  ...       ...                    ...  ...   \n",
       "5123691       Bandit2809     False                      #  ...   \n",
       "5123692      MathArt4All     False                  55419  ...   \n",
       "5123693           XoZXo2     False                      #  ...   \n",
       "5123694   Vie_de_martini     False                      #  ...   \n",
       "5123695   Millie96015868     False                Reality  ...   \n",
       "\n",
       "           retweet_author_id           retweet_id  retweeted_screen_name  \\\n",
       "0                   29816986  1364632754042802176         Maricopahealth   \n",
       "1                          #                    #                      #   \n",
       "2                  182037688  1364293582157307906           SteveStaeger   \n",
       "3                          #                    #                      #   \n",
       "4        1295748297529884673  1364087633538859008        jatinde45666597   \n",
       "...                      ...                  ...                    ...   \n",
       "5123691             16213139  1369444755751469057            abcadelaide   \n",
       "5123692  1215444012322172928  1369482754845466629               KizzyPhD   \n",
       "5123693             50308678  1369409097213296652             Ross_Greer   \n",
       "5123694                    #                    #                      #   \n",
       "5123695            178065733  1369469803795124225            ByMikeBaker   \n",
       "\n",
       "            user_mentions_id  user_mentions_screen_name  in_reply_to_user_id  \\\n",
       "0                   29816986             Maricopahealth                    #   \n",
       "1                          #                          #                    #   \n",
       "2                  182037688               SteveStaeger                    #   \n",
       "3                   36069538                   ochealth                    #   \n",
       "4        1295748297529884673            jatinde45666597                    #   \n",
       "...                      ...                        ...                  ...   \n",
       "5123691             16213139                abcadelaide                    #   \n",
       "5123692  1215444012322172928                   KizzyPhD                    #   \n",
       "5123693             50308678                 Ross_Greer                    #   \n",
       "5123694                    #                          #                    #   \n",
       "5123695            178065733                ByMikeBaker                    #   \n",
       "\n",
       "         in_reply_to_tweet_id in_reply_to_username reference_type  \\\n",
       "0                           #                    #      retweeted   \n",
       "1                           #                    #              #   \n",
       "2                           #                    #      retweeted   \n",
       "3                           #                    #              #   \n",
       "4                           #                    #      retweeted   \n",
       "...                       ...                  ...            ...   \n",
       "5123691                     #                    #      retweeted   \n",
       "5123692                     #                    #      retweeted   \n",
       "5123693                     #                    #      retweeted   \n",
       "5123694                     #                    #              #   \n",
       "5123695                     #                    #      retweeted   \n",
       "\n",
       "                reference_id  \n",
       "0        1364632754042802176  \n",
       "1                          #  \n",
       "2        1364293582157307906  \n",
       "3                          #  \n",
       "4        1364087633538859008  \n",
       "...                      ...  \n",
       "5123691  1369444755751469057  \n",
       "5123692  1369482754845466629  \n",
       "5123693  1369409097213296652  \n",
       "5123694                    #  \n",
       "5123695  1369469803795124225  \n",
       "\n",
       "[5123696 rows x 27 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_days"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = merged_days[merged_days['reference_type'] == 'quoted'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>credible</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>urls</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_author_id</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>retweeted_screen_name</th>\n",
       "      <th>user_mentions_id</th>\n",
       "      <th>user_mentions_screen_name</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_tweet_id</th>\n",
       "      <th>in_reply_to_username</th>\n",
       "      <th>reference_type</th>\n",
       "      <th>reference_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-02-24 18:05:18+00:00</td>\n",
       "      <td>1364637540330872838</td>\n",
       "      <td>1</td>\n",
       "      <td>1069764336279683072</td>\n",
       "      <td>SO many people don't realize how many inmates ...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>Chern like üßà</td>\n",
       "      <td>VisualsByChern</td>\n",
       "      <td>False</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1364636471387246592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-02-24 18:27:32+00:00</td>\n",
       "      <td>1364643136199299072</td>\n",
       "      <td>1</td>\n",
       "      <td>43545377</td>\n",
       "      <td>Just a reminder, we will have plenty of vaccin...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>Ann Bibby</td>\n",
       "      <td>anniegirl1138</td>\n",
       "      <td>False</td>\n",
       "      <td>Tea Time</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1364583293295943681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2021-02-24 18:42:16+00:00</td>\n",
       "      <td>1364646846434435074</td>\n",
       "      <td>1</td>\n",
       "      <td>139836595</td>\n",
       "      <td>Funny how he supports the Genocide of the Abor...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>mart chris</td>\n",
       "      <td>marchris52</td>\n",
       "      <td>False</td>\n",
       "      <td>BC üá®üá¶</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1364351771209043970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2021-02-24 19:05:30+00:00</td>\n",
       "      <td>1364652691750748166</td>\n",
       "      <td>1</td>\n",
       "      <td>754541231372275712</td>\n",
       "      <td>Gd what a genius idea I WILL be taking ur advi...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>Aidan Chase</td>\n",
       "      <td>HPEveryoneLives</td>\n",
       "      <td>False</td>\n",
       "      <td>#</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>427037072</td>\n",
       "      <td>waywardskyeyes</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1364289562734960641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2021-02-24 19:23:33+00:00</td>\n",
       "      <td>1364657233888309249</td>\n",
       "      <td>1</td>\n",
       "      <td>24785956</td>\n",
       "      <td>Think this will be a policy change, soon... ht...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>Mark I Williams M.D.</td>\n",
       "      <td>CameraGuyBakoCA</td>\n",
       "      <td>False</td>\n",
       "      <td>Bakersfield, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1364654324387872772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123639</th>\n",
       "      <td>2021-03-10 23:59:44+00:00</td>\n",
       "      <td>1369800166698582025</td>\n",
       "      <td>1</td>\n",
       "      <td>1100444916</td>\n",
       "      <td>That‚Äôs that chalkasain in you https://t.co/WBO...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>Amiri ambassador</td>\n",
       "      <td>treyfive_</td>\n",
       "      <td>False</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1369797672660594695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123642</th>\n",
       "      <td>2021-03-10 23:59:44+00:00</td>\n",
       "      <td>1369800167386357762</td>\n",
       "      <td>1</td>\n",
       "      <td>1244589997186887683</td>\n",
       "      <td>I Trump had acted responsibly and listened to ...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>Rand Paul's Neighbor - parody it's good to laugh</td>\n",
       "      <td>jbrown11871</td>\n",
       "      <td>False</td>\n",
       "      <td>Earth</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1369793211833741312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123660</th>\n",
       "      <td>2021-03-10 23:59:47+00:00</td>\n",
       "      <td>1369800181881962497</td>\n",
       "      <td>1</td>\n",
       "      <td>2422329920</td>\n",
       "      <td>Remember this in the Coming Dark Days; \\nIn 19...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>‚ùå‚ùå McFixit1 ‚ùå‚ùå</td>\n",
       "      <td>navstadt</td>\n",
       "      <td>False</td>\n",
       "      <td>Panther Burn MS</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1369644619747778562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123662</th>\n",
       "      <td>2021-03-10 23:59:48+00:00</td>\n",
       "      <td>1369800185786765314</td>\n",
       "      <td>1</td>\n",
       "      <td>3730426754</td>\n",
       "      <td>üí•BREAKING NEWSüí•\\n\\n#PostcardsToVoters #Resist ...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>Tall Miracle üá∫üá¶‚òÆÔ∏èüó≥üì¨</td>\n",
       "      <td>miracleguppy</td>\n",
       "      <td>False</td>\n",
       "      <td>Boise, ID USA</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1369774083118891009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123683</th>\n",
       "      <td>2021-03-10 23:59:51+00:00</td>\n",
       "      <td>1369800198571110406</td>\n",
       "      <td>1</td>\n",
       "      <td>184571032</td>\n",
       "      <td>Job openings at this Kroger: https://t.co/xDIx...</td>\n",
       "      <td>twitter.com,</td>\n",
       "      <td>#87, can you do somethin for me‚Ä¶</td>\n",
       "      <td>Droa26</td>\n",
       "      <td>False</td>\n",
       "      <td>#</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1369775813529321478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342898 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at             tweet_id  credible  \\\n",
       "8       2021-02-24 18:05:18+00:00  1364637540330872838         1   \n",
       "28      2021-02-24 18:27:32+00:00  1364643136199299072         1   \n",
       "45      2021-02-24 18:42:16+00:00  1364646846434435074         1   \n",
       "69      2021-02-24 19:05:30+00:00  1364652691750748166         1   \n",
       "84      2021-02-24 19:23:33+00:00  1364657233888309249         1   \n",
       "...                           ...                  ...       ...   \n",
       "5123639 2021-03-10 23:59:44+00:00  1369800166698582025         1   \n",
       "5123642 2021-03-10 23:59:44+00:00  1369800167386357762         1   \n",
       "5123660 2021-03-10 23:59:47+00:00  1369800181881962497         1   \n",
       "5123662 2021-03-10 23:59:48+00:00  1369800185786765314         1   \n",
       "5123683 2021-03-10 23:59:51+00:00  1369800198571110406         1   \n",
       "\n",
       "                   author_id  \\\n",
       "8        1069764336279683072   \n",
       "28                  43545377   \n",
       "45                 139836595   \n",
       "69        754541231372275712   \n",
       "84                  24785956   \n",
       "...                      ...   \n",
       "5123639           1100444916   \n",
       "5123642  1244589997186887683   \n",
       "5123660           2422329920   \n",
       "5123662           3730426754   \n",
       "5123683            184571032   \n",
       "\n",
       "                                                      text          urls  \\\n",
       "8        SO many people don't realize how many inmates ...  twitter.com,   \n",
       "28       Just a reminder, we will have plenty of vaccin...  twitter.com,   \n",
       "45       Funny how he supports the Genocide of the Abor...  twitter.com,   \n",
       "69       Gd what a genius idea I WILL be taking ur advi...  twitter.com,   \n",
       "84       Think this will be a policy change, soon... ht...  twitter.com,   \n",
       "...                                                    ...           ...   \n",
       "5123639  That‚Äôs that chalkasain in you https://t.co/WBO...  twitter.com,   \n",
       "5123642  I Trump had acted responsibly and listened to ...  twitter.com,   \n",
       "5123660  Remember this in the Coming Dark Days; \\nIn 19...  twitter.com,   \n",
       "5123662  üí•BREAKING NEWSüí•\\n\\n#PostcardsToVoters #Resist ...  twitter.com,   \n",
       "5123683  Job openings at this Kroger: https://t.co/xDIx...  twitter.com,   \n",
       "\n",
       "                                                     name         username  \\\n",
       "8                                            Chern like üßà   VisualsByChern   \n",
       "28                                              Ann Bibby    anniegirl1138   \n",
       "45                                             mart chris       marchris52   \n",
       "69                                            Aidan Chase  HPEveryoneLives   \n",
       "84                                   Mark I Williams M.D.  CameraGuyBakoCA   \n",
       "...                                                   ...              ...   \n",
       "5123639                                  Amiri ambassador        treyfive_   \n",
       "5123642  Rand Paul's Neighbor - parody it's good to laugh      jbrown11871   \n",
       "5123660                                    ‚ùå‚ùå McFixit1 ‚ùå‚ùå         navstadt   \n",
       "5123662                               Tall Miracle üá∫üá¶‚òÆÔ∏èüó≥üì¨     miracleguppy   \n",
       "5123683                  #87, can you do somethin for me‚Ä¶           Droa26   \n",
       "\n",
       "         verified         location  ...  retweet_author_id  retweet_id  \\\n",
       "8           False  California, USA  ...                  #           #   \n",
       "28          False         Tea Time  ...                  #           #   \n",
       "45          False           BC üá®üá¶   ...                  #           #   \n",
       "69          False                #  ...                  #           #   \n",
       "84          False  Bakersfield, CA  ...                  #           #   \n",
       "...           ...              ...  ...                ...         ...   \n",
       "5123639     False      Switzerland  ...                  #           #   \n",
       "5123642     False            Earth  ...                  #           #   \n",
       "5123660     False  Panther Burn MS  ...                  #           #   \n",
       "5123662     False    Boise, ID USA  ...                  #           #   \n",
       "5123683     False                #  ...                  #           #   \n",
       "\n",
       "         retweeted_screen_name  user_mentions_id  user_mentions_screen_name  \\\n",
       "8                            #                 #                          #   \n",
       "28                           #                 #                          #   \n",
       "45                           #                 #                          #   \n",
       "69                           #         427037072             waywardskyeyes   \n",
       "84                           #                 #                          #   \n",
       "...                        ...               ...                        ...   \n",
       "5123639                      #                 #                          #   \n",
       "5123642                      #                 #                          #   \n",
       "5123660                      #                 #                          #   \n",
       "5123662                      #                 #                          #   \n",
       "5123683                      #                 #                          #   \n",
       "\n",
       "         in_reply_to_user_id  in_reply_to_tweet_id in_reply_to_username  \\\n",
       "8                          #                     #                    #   \n",
       "28                         #                     #                    #   \n",
       "45                         #                     #                    #   \n",
       "69                         #                     #                    #   \n",
       "84                         #                     #                    #   \n",
       "...                      ...                   ...                  ...   \n",
       "5123639                    #                     #                    #   \n",
       "5123642                    #                     #                    #   \n",
       "5123660                    #                     #                    #   \n",
       "5123662                    #                     #                    #   \n",
       "5123683                    #                     #                    #   \n",
       "\n",
       "        reference_type         reference_id  \n",
       "8               quoted  1364636471387246592  \n",
       "28              quoted  1364583293295943681  \n",
       "45              quoted  1364351771209043970  \n",
       "69              quoted  1364289562734960641  \n",
       "84              quoted  1364654324387872772  \n",
       "...                ...                  ...  \n",
       "5123639         quoted  1369797672660594695  \n",
       "5123642         quoted  1369793211833741312  \n",
       "5123660         quoted  1369644619747778562  \n",
       "5123662         quoted  1369774083118891009  \n",
       "5123683         quoted  1369775813529321478  \n",
       "\n",
       "[342898 rows x 27 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Think this will be a policy change, soon... https://t.co/Pffvij3RKf'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.loc[84, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364657233888309249"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.loc[84, 'tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1364654324387872772'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.loc[84, 'reference_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_quote_texts = quotes.head(200).loc[:, 'text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file for writing (use 'a' instead of 'w' to append)\n",
    "with open(files_path + '/first_200_quotes.txt', 'w') as file:\n",
    "    # Loop through the list_of_quote_texts and write each text to a new line in the file\n",
    "    for text in list_of_quote_texts:\n",
    "        file.write(text + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPLIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies = merged_days[merged_days['reference_type'] == 'replied_to'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_replies = replies[replies.duplicated(subset=['author_id', 'in_reply_to_tweet_id'], keep=False)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_replies['in_reply_to_tweet_id'] = multiple_replies['in_reply_to_tweet_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_multiple_replies = multiple_replies.head(300).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groups_of_replies_for_opinion_change(multiple_replies):\n",
    "    # group the rows by the two columns\n",
    "    grouped_df = multiple_replies.groupby(['author_id', 'in_reply_to_tweet_id'])\n",
    "    # grouped_df = small_multiple_replies.groupby(['author_id', 'in_reply_to_tweet_id'])\n",
    "\n",
    "    groups_of_replies = grouped_df.groups\n",
    "\n",
    "    return groups_of_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_of_replies = create_groups_of_replies_for_opinion_change(multiple_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = PySentiStr()\n",
    "senti.setSentiStrengthPath(path_to_sentistrength_jar)\n",
    "senti.setSentiStrengthLanguageFolderPath(path_to_sentistrength_language_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opinion_change(rows_indices, replies, stop_words):\n",
    "    \"\"\"Function to detect whether an opinion change occured within a group of replies.\n",
    "\n",
    "    Args:\n",
    "        rows_indices (pandas.core.indexes.numeric.Int64Index): list of indices in the original dataframe\n",
    "                                                               where an opinion change has been detected\n",
    "                                                               (e.g. Int64Index([1848965, 1850146, 1850687], dtype='int64'))\n",
    "\n",
    "    Returns:\n",
    "        bool: boolean value which confirms or denies the existence of an opinion change within a group\n",
    "    \"\"\"    \n",
    "    texts = [ clean_text(replies.loc[index, 'text'], stop_words) for index in rows_indices ]\n",
    "\n",
    "    sentiments = senti.getSentiment(texts, score='scale')\n",
    "    sentiments = np.array(sentiments)\n",
    "\n",
    "    positive = np.any(sentiments > 0)\n",
    "    negative = np.any(sentiments < 0)\n",
    "\n",
    "    return positive and negative, sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT NOTE:\n",
    "\n",
    "THERE IS NO NEED TO RUN THE COMMENTED CELLS BETWEEN THE LINES BELOW!\n",
    "It took more than 15 minutes when I ran the creation of the opinion_changes dictionary on the whole replies dataset...\n",
    "\n",
    "I saved the resulting dictionary into a JSON file, which can be found in the root directory of the project. This can be imported into a dictionary with ease (code can be found in the next parts of the notebook)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counter = 0\n",
    "progress = 0.01\n",
    "\n",
    "def print_progress(groups_of_replies):\n",
    "    \"\"\"Function that prints the progress of the computation of the opinion_changes dictionary,\n",
    "    as it takes a lot of time for large datasets.\n",
    "\n",
    "    Args:\n",
    "        groups_of_replies (dict): dictionary of replies grouped by some columns\n",
    "    \"\"\"    \n",
    "    global group_counter\n",
    "    global progress\n",
    "    group_counter += 1\n",
    "\n",
    "    if ((group_counter / len(groups_of_replies)) >= progress):\n",
    "        print(f\"Progress: {group_counter} / {len(groups_of_replies)} groups of replies processed.\")\n",
    "        progress += 0.01\n",
    "    if group_counter == len(groups_of_replies):\n",
    "        print(\"All groups have been processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opinion_changes(groups_of_replies, progress_printing, stop_words):\n",
    "    \"\"\"Function to create the data structure associated with the groups (pairs of user id-s who interacted through replies)\n",
    "    where an opinio change occured, i.e. when, between their interactions (e.g. one's replies to the other's original post),\n",
    "    there have been both positive and negative opinions.\n",
    "\n",
    "    Args:\n",
    "        groups_of_replies (dict): dictionary of replies grouped by some columns\n",
    "        progress_printing (bool): boolean value indicating whether the user wishes to print the progress of the groups processed or not\n",
    "                                  (this can be useful to track when processing large datasets - they usually take a lot of time)\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary where the keys represent the groups where opinion changes occured (as tuples) and the values are\n",
    "              lists of the sentiments associated to the interactions within each group\n",
    "    \"\"\"    \n",
    "    if progress_printing == True:\n",
    "        opinion_changes = {}\n",
    "        for group, rows_indices in groups_of_replies.items():\n",
    "            print_progress(groups_of_replies)\n",
    "            if opinion_change(rows_indices, replies, stop_words)[0] == True:\n",
    "                opinion_changes[group] = opinion_change(rows_indices, replies, stop_words)[1].tolist()\n",
    "    else:\n",
    "        print(\"Gradual progress will not be printed.\")\n",
    "        print(\"If you wish to see it, change the value of the progress_printing input parameter to True.\")\n",
    "        opinion_changes = { group: opinion_change(rows_indices, replies, stop_words)[1].tolist() for group, rows_indices in groups_of_replies.items() \n",
    "                        if opinion_change(rows_indices, replies, stop_words)[0] == True }\n",
    "    \n",
    "    return opinion_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_printing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 56 / 5587 groups of replies processed.\n",
      "Progress: 112 / 5587 groups of replies processed.\n",
      "Progress: 168 / 5587 groups of replies processed.\n",
      "Progress: 224 / 5587 groups of replies processed.\n",
      "Progress: 280 / 5587 groups of replies processed.\n",
      "Progress: 336 / 5587 groups of replies processed.\n",
      "Progress: 392 / 5587 groups of replies processed.\n",
      "Progress: 447 / 5587 groups of replies processed.\n",
      "Progress: 503 / 5587 groups of replies processed.\n",
      "Progress: 559 / 5587 groups of replies processed.\n",
      "Progress: 615 / 5587 groups of replies processed.\n",
      "Progress: 671 / 5587 groups of replies processed.\n",
      "Progress: 727 / 5587 groups of replies processed.\n",
      "Progress: 783 / 5587 groups of replies processed.\n",
      "Progress: 839 / 5587 groups of replies processed.\n",
      "Progress: 894 / 5587 groups of replies processed.\n",
      "Progress: 950 / 5587 groups of replies processed.\n",
      "Progress: 1006 / 5587 groups of replies processed.\n",
      "Progress: 1062 / 5587 groups of replies processed.\n",
      "Progress: 1118 / 5587 groups of replies processed.\n",
      "Progress: 1174 / 5587 groups of replies processed.\n",
      "Progress: 1230 / 5587 groups of replies processed.\n",
      "Progress: 1286 / 5587 groups of replies processed.\n",
      "Progress: 1341 / 5587 groups of replies processed.\n",
      "Progress: 1397 / 5587 groups of replies processed.\n",
      "Progress: 1453 / 5587 groups of replies processed.\n",
      "Progress: 1509 / 5587 groups of replies processed.\n",
      "Progress: 1565 / 5587 groups of replies processed.\n",
      "Progress: 1621 / 5587 groups of replies processed.\n",
      "Progress: 1677 / 5587 groups of replies processed.\n",
      "Progress: 1732 / 5587 groups of replies processed.\n",
      "Progress: 1788 / 5587 groups of replies processed.\n",
      "Progress: 1844 / 5587 groups of replies processed.\n",
      "Progress: 1900 / 5587 groups of replies processed.\n",
      "Progress: 1956 / 5587 groups of replies processed.\n",
      "Progress: 2012 / 5587 groups of replies processed.\n",
      "Progress: 2068 / 5587 groups of replies processed.\n",
      "Progress: 2124 / 5587 groups of replies processed.\n",
      "Progress: 2179 / 5587 groups of replies processed.\n",
      "Progress: 2235 / 5587 groups of replies processed.\n",
      "Progress: 2291 / 5587 groups of replies processed.\n",
      "Progress: 2347 / 5587 groups of replies processed.\n",
      "Progress: 2403 / 5587 groups of replies processed.\n",
      "Progress: 2459 / 5587 groups of replies processed.\n",
      "Progress: 2515 / 5587 groups of replies processed.\n",
      "Progress: 2571 / 5587 groups of replies processed.\n",
      "Progress: 2626 / 5587 groups of replies processed.\n",
      "Progress: 2682 / 5587 groups of replies processed.\n",
      "Progress: 2738 / 5587 groups of replies processed.\n",
      "Progress: 2794 / 5587 groups of replies processed.\n",
      "Progress: 2850 / 5587 groups of replies processed.\n",
      "Progress: 2906 / 5587 groups of replies processed.\n",
      "Progress: 2962 / 5587 groups of replies processed.\n",
      "Progress: 3017 / 5587 groups of replies processed.\n",
      "Progress: 3073 / 5587 groups of replies processed.\n",
      "Progress: 3129 / 5587 groups of replies processed.\n",
      "Progress: 3185 / 5587 groups of replies processed.\n",
      "Progress: 3241 / 5587 groups of replies processed.\n",
      "Progress: 3297 / 5587 groups of replies processed.\n",
      "Progress: 3353 / 5587 groups of replies processed.\n",
      "Progress: 3409 / 5587 groups of replies processed.\n",
      "Progress: 3464 / 5587 groups of replies processed.\n",
      "Progress: 3520 / 5587 groups of replies processed.\n",
      "Progress: 3576 / 5587 groups of replies processed.\n",
      "Progress: 3632 / 5587 groups of replies processed.\n",
      "Progress: 3688 / 5587 groups of replies processed.\n",
      "Progress: 3744 / 5587 groups of replies processed.\n",
      "Progress: 3800 / 5587 groups of replies processed.\n",
      "Progress: 3856 / 5587 groups of replies processed.\n",
      "Progress: 3911 / 5587 groups of replies processed.\n",
      "Progress: 3967 / 5587 groups of replies processed.\n",
      "Progress: 4023 / 5587 groups of replies processed.\n",
      "Progress: 4079 / 5587 groups of replies processed.\n",
      "Progress: 4135 / 5587 groups of replies processed.\n",
      "Progress: 4191 / 5587 groups of replies processed.\n",
      "Progress: 4247 / 5587 groups of replies processed.\n",
      "Progress: 4302 / 5587 groups of replies processed.\n",
      "Progress: 4358 / 5587 groups of replies processed.\n",
      "Progress: 4414 / 5587 groups of replies processed.\n",
      "Progress: 4470 / 5587 groups of replies processed.\n",
      "Progress: 4526 / 5587 groups of replies processed.\n",
      "Progress: 4582 / 5587 groups of replies processed.\n",
      "Progress: 4638 / 5587 groups of replies processed.\n",
      "Progress: 4694 / 5587 groups of replies processed.\n",
      "Progress: 4749 / 5587 groups of replies processed.\n",
      "Progress: 4805 / 5587 groups of replies processed.\n",
      "Progress: 4861 / 5587 groups of replies processed.\n",
      "Progress: 4917 / 5587 groups of replies processed.\n",
      "Progress: 4973 / 5587 groups of replies processed.\n",
      "Progress: 5029 / 5587 groups of replies processed.\n",
      "Progress: 5085 / 5587 groups of replies processed.\n",
      "Progress: 5141 / 5587 groups of replies processed.\n",
      "Progress: 5196 / 5587 groups of replies processed.\n",
      "Progress: 5252 / 5587 groups of replies processed.\n",
      "Progress: 5308 / 5587 groups of replies processed.\n",
      "Progress: 5364 / 5587 groups of replies processed.\n",
      "Progress: 5420 / 5587 groups of replies processed.\n",
      "Progress: 5476 / 5587 groups of replies processed.\n",
      "Progress: 5532 / 5587 groups of replies processed.\n",
      "All groups have been processed.\n"
     ]
    }
   ],
   "source": [
    "opinion_changes = create_opinion_changes(groups_of_replies, progress_printing, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_opinion_changes_to_JSON(opinion_changes, path):\n",
    "    \"\"\"Function to save the dictionary pf opinion changes to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        opinion_changes (dict): dictionary with opinion changes\n",
    "        path (str): path where you wish to save the JSON file\n",
    "    \"\"\"    \n",
    "    # create a new dictionary with string keys\n",
    "    opinion_changes_for_JSON_file = {str(key): value for key, value in opinion_changes.items() }\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(opinion_changes_for_JSON_file, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_opinion_changes_to_JSON(opinion_changes, path_to_replies_opinion_changes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opinion_changes(path_to_replies_opinion_changes):\n",
    "    \"\"\"Function that generates a dictionary based on a JSON file which contains the opinion changes within the replies of the dataset.\n",
    "\n",
    "    Args:\n",
    "        path_to_replies_opinion_changes (str): path to the JSON file associated with the opinion changes within the replies\n",
    "                                               (e.g. /your/path/to/research-internship)\n",
    "\n",
    "    Returns:\n",
    "        dict: the original dictionary containing opinion changes from replies\n",
    "    \"\"\"    \n",
    "    with open(path_to_replies_opinion_changes) as f:\n",
    "        # Load the JSON data into a Python dictionary\n",
    "        opinion_changes_from_file = json.load(f)\n",
    "        # Create a new dictionary with tuple keys\n",
    "        original_opinion_changes = {}\n",
    "        for key in opinion_changes_from_file:\n",
    "            # Convert the string key to a tuple\n",
    "            new_key = eval(key)\n",
    "            # Add the key-value pair to the new dictionary\n",
    "            original_opinion_changes[new_key] = opinion_changes_from_file[key]\n",
    "            \n",
    "    return original_opinion_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_changes = load_opinion_changes(path_to_replies_opinion_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of opinion changes out of the interactions where one user replied multiple times to a source tweet:\n",
      "15.7%.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of opinion changes out of the interactions where one user replied multiple times to a source tweet:\")\n",
    "print(f\"{round(len(opinion_changes) / len(groups_of_replies) * 100, 1)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_opinion_change(opinion_changes):\n",
    "    \"\"\"Function that returns the group (pair of user id-s) which interacted more than once in the context of a single source tweet,\n",
    "    i.e. one user posted more than one reply to the same source tweet, where the user who reacted had the most drastic opinion change,\n",
    "    based on the previously computed sentiments of the text.\n",
    "\n",
    "    Args:\n",
    "        opinion_changes (dict): dictionary with opinion changes\n",
    "\n",
    "    Returns:\n",
    "        tuple: pair of user id-s where the biggest opinion change occured\n",
    "        str: type of change that occured, e.g. one user tends to agree with the source tweet after some time, \n",
    "             when initially he disagreed or vice-versa\n",
    "    \"\"\"    \n",
    "    change_type = 'negative'\n",
    "    biggest_change = 0\n",
    "    target_group = tuple()\n",
    "    for group, sentiments in opinion_changes.items():\n",
    "        change = max(biggest_change, max(sentiments) - min(sentiments))\n",
    "        if change > biggest_change:\n",
    "            biggest_change = change\n",
    "            target_group = group\n",
    "    \n",
    "    min_sentiment_index = opinion_changes[target_group].index(min(opinion_changes[target_group]))\n",
    "    max_sentiment_index = opinion_changes[target_group].index(max(opinion_changes[target_group]))\n",
    "    change_type = 'positive' if min_sentiment_index < max_sentiment_index else change_type\n",
    "\n",
    "    return target_group, change_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_group, change_type = biggest_opinion_change(opinion_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(932012546, 1366061818699989002)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replies_with_biggest_opinion_change(multiple_replies, target_group):\n",
    "    \"\"\"Function that queries the multiple_replies dataset and returns a list of the actual texts that the pair of users posted.\n",
    "     The user id-s of these users are passed on as input parameters (the target group).\n",
    "\n",
    "    Args:\n",
    "        replies (pandas Dataframe): the dataframe with the replies\n",
    "        target_group (tuple): pair of user id-s whose posts had the biggest opinion change\n",
    "\n",
    "    Returns:\n",
    "        list: list of texts posted by the 2 users\n",
    "    \"\"\"    \n",
    "    condition1 = multiple_replies['author_id'] == target_group[0]\n",
    "    condition2 = multiple_replies['in_reply_to_tweet_id'] == target_group[1]\n",
    "\n",
    "    return multiple_replies[condition1 & condition2].loc[:, 'text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies_biggest_change = replies_with_biggest_opinion_change(multiple_replies, target_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@KATIEDOLL1201 @daulan @SandySue1958 I've been taking vaccines since I was very young..  I got the vax -my SIL was SORRY she didn't.  My mom and her sis just got both covid shots -NP.  Mom's 90, her sis it is 94.  Grandma was born in 1899, saw the 1st pandemic.. She loved vaccines. She lived to 94, maybe that's why.\",\n",
       " \"@KATIEDOLL1201 @daulan @SandySue1958 Sorry, they're being so hard on you, but the 'majority' of people who get Shingles say it is very painful, and the 'majority' of people who have the vaccine do not have an issue.  That is by the numbers.  And right now there is soo much misinformation being spread- It's just sad.\"]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies_biggest_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opinion_change_type(opinion_changes, group):\n",
    "    \"\"\"Function to detect what type of opinion change occured in the case of a group (pair of user ids-s) which interacted\n",
    "    through replies\n",
    "\n",
    "    Args:\n",
    "        opinion_changes (dict): dictionary with opinion changes\n",
    "        group (tuple): pair of user id-s that interacted through replies and the respondent changed his viewpoint w.r.t. a source tweet\n",
    "\n",
    "    Returns:\n",
    "        str: either 'positive' (if the respondent now agrees after initially disagreeing) or 'negative'\n",
    "    \"\"\"    \n",
    "    min_sentiment_index = opinion_changes[group].index(min(opinion_changes[group]))\n",
    "    max_sentiment_index = opinion_changes[group].index(max(opinion_changes[group]))\n",
    "    \n",
    "    change_type = 'negative'\n",
    "    change_type = 'positive' if min_sentiment_index < max_sentiment_index else change_type\n",
    "\n",
    "    return change_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask indicating what type of opinion change each group has\n",
    "mask = {group: opinion_change_type(opinion_changes, group) for group in opinion_changes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_count_in_dict(dict, value_to_count):\n",
    "    \"\"\"Function to count the occurences of a certain value in a dictionary.\n",
    "\n",
    "    Args:\n",
    "        dict (dict): dictionary where we need to count the occurences of a value\n",
    "        value_to_count (any): value to be counted\n",
    "\n",
    "    Returns:\n",
    "        int: number of occurences of value_to_count\n",
    "    \"\"\"    \n",
    "    # Create a reverse dictionary that maps values to their frequencies\n",
    "    reverse_dict = defaultdict(int)\n",
    "    for value in dict.values():\n",
    "        reverse_dict[value] += 1\n",
    "\n",
    "    # Count the occurrences of the specific value\n",
    "    count = reverse_dict.get(value_to_count, 0)\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive opinion changes out of:\n",
      "- the interactions where one user replied multiple times to a source tweet and an opinion change was detected => 46.4%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of positive opinion changes out of:\")\n",
    "print(f\"- the interactions where one user replied multiple times to a source tweet and an opinion change was detected => {round(value_count_in_dict(mask, 'positive') / len(mask) * 100, 1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of negative opinion changes out of:\n",
      "- the interactions where one user replied multiple times to a source tweet and an opinion change was detected => 53.6%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of negative opinion changes out of:\")\n",
    "print(f\"- the interactions where one user replied multiple times to a source tweet and an opinion change was detected => {round(value_count_in_dict(mask, 'negative') / len(mask) * 100, 1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the distribution of the tweets per hour, I will parse the \"created_at\" column, extract the hour property and create a separate column in each dataframe. I will place it next to the \"created_at\" column in order to be easily verifiable. Data originates frmo the Twitter API, so it comes in a standard ISO 8601 format, which can be easily parsed using the parser module from the dateutil package.\n",
    "\n",
    "Note: the cell below runs for approximately 2m30' on my machine (~25-30 seconds for each file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, day in days.items():\n",
    "#     if 'hour' not in day.columns:\n",
    "#         day.insert(1, 'hour', day['created_at'].apply(lambda date: parser.parse(date).hour))\n",
    "#         print(f\"New 'hour' column inserted in the {key} dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, day in days.items():\n",
    "#     if 'hour' not in day.columns:\n",
    "#         hours = []\n",
    "#         for time in day.loc[:,\"created_at\"]:\n",
    "#             hour = parser.parse(time).hour\n",
    "#             hours.append(hour)\n",
    "#         day.insert(1, \"hour\", hours, True)\n",
    "#         print(key + \" - added 'hour' column\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final distribution is made up of the sum of all individual days' distributions. I save a figure in the graphs/ folder for each day, as well as an overall distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_distribution = pd.Series(0, index=days['1-3-2021'].loc[:,'hour'].sort_values(ascending=True).unique())\n",
    "# for key, day in days.items():\n",
    "#     hour_column_ascending = day.loc[:,\"hour\"].sort_values(ascending=True)\n",
    "#     distribution = hour_column_ascending.value_counts()[hour_column_ascending.unique()]\n",
    "#     final_distribution = final_distribution.add(distribution)\n",
    "#     axes = distribution.plot(kind='bar')\n",
    "#     figure_path = f\"{covaxxy_longitudinal_analysis_graphs}/{key}_distribution.png\"\n",
    "#     axes.figure.savefig(figure_path)\n",
    "#     plt.close()\n",
    "# axes = final_distribution.plot(kind='bar')\n",
    "# figure_path = f\"{covaxxy_longitudinal_analysis_graphs}/overall_distribution.png\"\n",
    "# axes.figure.savefig(figure_path)\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "243101c165aceacaf115b49fc146265224cf91574f24df3021157e0d2dabdb2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
